{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"sap_storing.csv\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We laden hieronder de test database in, we willen globaal naar de data kijken en gebruiken daarom hiervoor nog niet de gehele database. Wat meteen opvalt is dat er een groot aantal kolommen zijn: namelijk 140. Dit zijn dus 140 variabelen die we mogelijk mee moeten nemen verder in ons project. Bij deze stap in het project willen we gaan kijken welke variabelen kansrijk zijn om bijvoorbeeld als feature- of targetvariabele aangewezen kunnen worden. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In eerste instantie maakt de dataset een redelijk rommelige indruk, dit komt waarschijnlijk door de ietwat verwarrende namen van de kolommen en de verschillende datatypes waarin de waardes worden weergegeven. Het kan handig zijn om meer overzicht te creeÃ«ren binnen de dataset, door bijvoorbeeld kolommen een helderdere naam te geven. Gelukkig hebben we wel een legenda gekregen die ons uitlegt wat elke kolom in de dataset betekent. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We willen onderzoeken hoeveel null waardes er zijn binnen de dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(3770/(79 * 140)) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ruim 30% van de dataset bestaat uit null waardes. Ook zijn er kolommen die compleet leeg zijn, hier hebben we niks aan wanneer we de data gaan analyseren. Daarom hebben we gekozen om alle kolommen te droppen behalve de kolommen waarin minstens 50 van de 79 gevuld zijn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.count().idxmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = data.dropna(axis = 'columns', thresh=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De kolom die nu de meeste nulwaardes heeft is de kolom stm_progfh_hz, deze kolom heeft 27 null waardes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.count().idxmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[['stm_progfh_hz']].isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We willen uiteindelijk een voorspellend model maken en hiervoor hebben we target en feature variabelen nodig. Om op zoek te gaan naar welke variabelen kansrijk zijn om aangewezen te worden als feature- of target variabelen bekijken we de correlatie tussen de kolommen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bij de volgende stap data preperation gaan we kijken welke kolommen wel en niet nuttig zijn om te behouden. Niet elke correlatie in de boven getoonde heeft een echte betekenis omdat er tussen sommige kolommen gewoon geen verband te ontdekken is. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We willen zelf kijken of sommigen kolommen met elkaar gecorreleert zijn; zo wilden we de correlatie tussen de prioriteit van een melding en de locatie ervan. Dit zou aan kunnen tonen dat meldingen met een hoge prioriteit vaker voorkomen in een bepaald geografisch gebied. De correlatie is -0.3, dit is een zwakke correlatie en dus niet perse een verband wat we mee willen nemen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor = df1[['stm_prioriteit', 'stm_geo_gst']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor1 = df1[['stm_fh_duur', 'stm_prioriteit', 'stm_reactie_duur']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor1.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ook zijn er een aantal kolommen die redundant zijn, hieronder tonen we bijvoorbeeld meld ddt, meldtijd en melddatum. We zien dat meldtijd en melddatum eigenlijk samen uit dezelfde info bestaan als meld ddt. Deze kolommen kunnen we in een volgende stap gaan samenvoegen of we moeten een aantal kolommen droppen om deze dubbele waardes te vermijden. Dit geldt ook voor geo_st en geo_mld."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[['stm_sap_meld_ddt', 'stm_sap_meldtijd', 'stm_sap_melddatum']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[['stm_geo_gst', 'stm_geo_mld']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uiteindelijk willen we de reparatie duur gaan voorspellen; dit wordt onze target variabele. We moeten hiervoor waarschijnlijk een nieuwe variabele aanmaken die deze reparatie duur gaat uitrekenen aan de hand van twee tijd variabelen: bijvoorbeeld de meldtijd en het tijdstip wanneer het probleem opgelost is. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
