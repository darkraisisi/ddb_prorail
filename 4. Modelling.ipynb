{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In deze stap gaan we verschillende modellen toepassen op onze data en zo vergelijken om te kijken welk model het beste werkt op de data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eerst herhalen we hieronder een aantal stappen die we al eerder hebben uitgevoerd. (Voor toelichting: zie 3 Data preparation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import math\n",
    "\n",
    "import datetime as date\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "n_jobs = 16 #set number of jobs equal or -1 the amount of cpu cores you have to speed up this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usefullcols = ['stm_mon_nr','stm_sap_meld_ddt','stm_status_melding_sap','stm_km_van_mld','stm_km_tot_mld','stm_km_van_gst',\n",
    "'stm_km_tot_gst','stm_fh_tijd','stm_sap_melddatum','stm_aanngeb_tijd','stm_aanntpl_tijd','stm_arbeid',\n",
    "'stm_progfh_in_tijd','stm_progfh_in_invoer_tijd','stm_progfh_in_duur','stm_sap_storeindtijd','stm_progfh_gw_tijd',\n",
    "'stm_reactie_duur','stm_progfh_gw_duur','stm_progfh_gw_teller','stm_afspr_aanvangdd','stm_afspr_aanvangtijd',\n",
    "'stm_fh_duur','stm_evb','stm_sap_meldtijd','stm_sap_meldtekst_lang','stm_prioriteit','stm_oh_pg_gst',\n",
    "'stm_sap_meldtekst','stm_techn_gst','stm_contractgeb_gst','stm_tao_indicator','stm_geo_mld','stm_functiepl_mld',\n",
    "'stm_geo_mld_uit_functiepl','stm_aanngeb_ddt','stm_aanngeb_dd','stm_oorz_code','stm_oorz_groep','stm_oorz_tkst',\n",
    "'stm_fh_dd','stm_fh_status','stm_geo_gst','stm_functiepl_gst','stm_geo_gst_uit_functiepl','stm_fh_ddt',\n",
    "'stm_aanntpl_dd','stm_techn_mld','stm_sap_storeinddatum','stm_equipm_nr_mld','stm_equipm_soort_mld',\n",
    "'stm_equipm_omschr_mld','stm_sap_storeind_ddt','stm_contractgeb_mld','stm_equipm_nr_gst','stm_equipm_soort_gst',\n",
    "'stm_equipm_omschr_gst','stm_progfh_in_invoer_dat','stm_progfh_in_datum','stm_oorz_tekst_kort','stm_dstrglp_naar',\n",
    "'stm_tao_indicator_vorige','stm_vl_post','stm_dstrglp_van','stm_pplg_van','stm_tao_soort_mutatie',\n",
    "'stm_progfh_gw_lwd_tijd','stm_pplg_naar','stm_progfh_gw_lwd_datum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('sap_storing_data_hu_project.csv',usecols=usefullcols, low_memory=True)\n",
    "# df = pd.read_csv('sap_storing.csv',usecols=usefullcols, low_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['stm_prioriteit','stm_oorz_code','stm_oorz_groep','stm_equipm_soort_*','stm_geo_*']\n",
    "target = 'duur'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = date.datetime.today()\n",
    "zeroTimeDiff = now - now\n",
    "\n",
    "df.drop_duplicates(subset=['stm_mon_nr'], keep='last',inplace = True)\n",
    "\n",
    "df['stm_aanntpl_ddt'] = pd.to_datetime(df['stm_aanntpl_dd']+' '+df['stm_aanntpl_tijd'], format='%d/%m/%Y %H:%M:%S')\n",
    "df['stm_fh_ddt'] = pd.to_datetime(df['stm_fh_ddt'], format='%d/%m/%Y %H:%M:%S')\n",
    "\n",
    "df.dropna(subset=['stm_aanntpl_dd','stm_aanntpl_tijd','stm_fh_ddt'],inplace=True)\n",
    "\n",
    "df['duur'] = df['stm_fh_ddt'] - df['stm_aanntpl_ddt']\n",
    "df.dropna(subset=['duur'],inplace=True)\n",
    "\n",
    "# Meldingen waar de oplossing in de toekomst is zijn onzin.\n",
    "# df[df['stm_sap_storeind_ddt'] >= now][['stm_sap_storeind_ddt','stm_sap_meld_ddt']]\n",
    "# df.drop(df[df['stm_sap_storeind_ddt'] >= now][['stm_sap_storeind_ddt','stm_sap_meld_ddt']].index,inplace=True)\n",
    "\n",
    "# Rijen waar het probleem sneller is opgelost dan 5 minuten (en ook de meldingen tijd) zijn onbetrouwbaar.\n",
    "df.drop(df[df['duur'] <= date.timedelta(minutes=5)].index, inplace = True)\n",
    "\n",
    "# # Alles wat langer dan een dag duurt is niet urgent genoeg en dus niet nuttig.\n",
    "df.drop(df[df['duur'] > date.timedelta(hours=6)].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dubbleCol = ['stm_equipm_omschr_*', 'stm_equipm_soort_*', 'stm_equipm_nr_*', \n",
    "             'stm_geo_*_uit_functiepl', 'stm_functiepl_*', 'stm_geo_*',\n",
    "            'stm_km_van_*','stm_km_tot_*',\n",
    "            'stm_contractgeb_*','stm_techn_*']\n",
    "original = 'mld'\n",
    "optional = ['gst'] # Order of least to most important\n",
    "for colPH in dubbleCol:\n",
    "    colOg = colPH.replace('*',original)\n",
    "    \n",
    "    for option in optional:\n",
    "        colOp = colPH.replace('*',option)\n",
    "        df[colPH] = np.where(df[colOp].isna(), df[colOg], df[colOp])\n",
    "        df.drop(columns=[colOp],inplace=True)\n",
    "    df.drop(columns=[colOg],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['stm_prioriteit'] = df['stm_prioriteit'].fillna(1) # Laagste prio\n",
    "df['stm_oorz_code'] = df['stm_oorz_code'].fillna(299) # 'Niet gemeld' code\n",
    "df['stm_oorz_groep'] = df['stm_oorz_groep'].fillna('x')\n",
    "df['stm_fh_status'] = df['stm_fh_status'].fillna(1) # Median of values\n",
    "df['stm_aanngeb_tijd'] = df['stm_aanngeb_tijd'].fillna(df['stm_sap_meldtijd']) # Aannemer beltijd gelijk met melding zetten.\n",
    "df['stm_progfh_in_invoer_tijd'] = df['stm_progfh_in_invoer_tijd'].fillna(df['stm_aanngeb_tijd']) # Tijd van prognose op beltijd zetten.\n",
    "df['stm_equipm_nr_*'] = df['stm_equipm_nr_*'].fillna(0)\n",
    "df['stm_equipm_soort_*'] = df['stm_equipm_soort_*'].fillna('x')\n",
    "df['stm_contractgeb_*'] = df['stm_contractgeb_*'].fillna(0)\n",
    "df['stm_progfh_gw_teller'] = df['stm_progfh_gw_teller'].fillna(0)\n",
    "\n",
    "df['stm_prioriteit'] = df['stm_prioriteit'].astype(int)\n",
    "df['stm_oorz_code'] = df['stm_oorz_code'].astype(int)\n",
    "df['stm_fh_status'] = df['stm_fh_status'].astype(int)\n",
    "df['stm_fh_duur'] = df['stm_fh_duur'].astype(int)\n",
    "df['stm_progfh_gw_teller'] = df['stm_progfh_gw_teller'].astype(int)\n",
    "df['stm_equipm_nr_*'] = df['stm_equipm_nr_*'].astype(int)\n",
    "df['stm_contractgeb_*'] = df['stm_contractgeb_*'].astype(int)\n",
    "\n",
    "df['duur'] = df['duur'].apply(lambda x: x.seconds / 60)\n",
    "df['duur'] = df['duur'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Baseline model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We beginnen met het baseline model. Dit is het meest simpele model waarvan de uitkomst is dat alle storingen in 2 uur en 17 minuten opgelost zijn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score en RMSE\n",
    "Echter kunnen we aan de score en de RMSE aflezen dat het baseline model niet erg geschikt is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amntInTime = df[df['duur'] < date.timedelta(hours=2,minutes=17).seconds / 60].count()[0]\n",
    "total = df.shape[0]\n",
    "baseline = date.timedelta(hours=2,minutes=17).seconds / 60\n",
    "pred = [int(baseline)]*df[['duur']].shape[0]\n",
    "\n",
    "baseline = date.timedelta(hours=2,minutes=17)\n",
    "baseline = baseline.seconds / 60\n",
    "pred = [int(baseline)]*df[[target]].shape[0]\n",
    "\n",
    "print('Score :', r2_score(df[[target]],pred))\n",
    "print('Root mean squared error:',np.sqrt(mean_squared_error(df['duur'],pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset trainen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_ozgr = LabelEncoder()\n",
    "le_ozgr.fit(df['stm_oorz_groep'].unique())\n",
    "df['stm_oorz_groep'] = le_ozgr.transform(df['stm_oorz_groep'])\n",
    "# df['stm_oorz_groep'].unique()\n",
    "pickle.dump(le_ozgr, open('le_ozgr', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_equipsrt = LabelEncoder()\n",
    "le_equipsrt.fit(df['stm_equipm_soort_*'].unique())\n",
    "df['stm_equipm_soort_*'] = le_equipsrt.transform(df['stm_equipm_soort_*'])\n",
    "# df['stm_equipm_soort_*'].unique()\n",
    "pickle.dump(le_equipsrt, open('le_equipsrt', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  2.1  Get_dummies\n",
    "Hieronder gebruiken we get_dummies op verschillende feature kolommen, wat we hier doen is het omzetten van categoriale data naar nominale waardes. We doen dit niet bij stm_prioriteit omdat het voor deze kolom belangrijk is dat het zijn volgorde behoudt, de waarde van de prioriteit zegt iets over de volgordelijkheid. Wanneer je hierop get_dummies zou toepassen, zou je juist deze volgordelijkheid verliezen. Bij de andere kolommen is dit niet zo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dOC = pd.get_dummies(df['stm_oorz_code'],prefix='oorz_code')\n",
    "dOG = pd.get_dummies(df['stm_oorz_groep'],prefix='oorz_groep')\n",
    "eqs = pd.get_dummies(df['stm_equipm_soort_*'])\n",
    "geo = pd.get_dummies(df['stm_geo_*'],prefix='geo')\n",
    "\n",
    "dummies = pd.concat([df['stm_prioriteit'],dOC, dOG, eqs, geo],axis=1)\n",
    "\n",
    "display(dummies)\n",
    "dummies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " X = dummies\n",
    "#X = df[features]\n",
    "Y = df[target]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=54)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train,y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Lineaire regressie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score en RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linearModel = linear_model.LinearRegression().fit(x_train,y_train)\n",
    "linYPrediction = linearModel.predict(x_test)\n",
    "print(f'Score: {linearModel.score(x_test,y_test)}')\n",
    "print(f'Mean squared error: {np.sqrt(mean_squared_error(y_test,linYPrediction))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(x_test[:5])\n",
    "display(y_test[:5])\n",
    "linYPrediction[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Ridge regressie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score en RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ridgeModel = linear_model.Ridge(alpha=1).fit(x_train,y_train)\n",
    "ridgeYPrediction = ridgeModel.predict(x_test)\n",
    "print(f'Score: {ridgeModel.score(x_test,y_test)}')\n",
    "print(f'Mean squared error: {np.sqrt(mean_squared_error(y_test,ridgeYPrediction))}')\n",
    "print(ridgeModel.get_params())\n",
    "print(ridgeModel.get_params(deep=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. KNearest Neighbours regressie\n",
    "### Score en RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knearestModel = KNeighborsRegressor(n_neighbors=2,n_jobs=n_jobs).fit(x_train,y_train)\n",
    "knearestYPrediction = knearestModel.predict(x_test)\n",
    "print(f'Score: {knearestModel.score(x_test,y_test)}')\n",
    "print(f'Mean squared error: {np.sqrt(mean_squared_error(y_test,knearestYPrediction))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias/Variance trade-off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_neighbours = 10\n",
    "# scores_train = np.zeros(max_neighbours)\n",
    "# scores_test = np.zeros(max_neighbours)\n",
    "# variance = np.zeros(max_neighbours)\n",
    "\n",
    "# neighbours = range(1, max_neighbours + 1)\n",
    "# for n in neighbours:\n",
    "#     print(f\"Starting with run:{n}\")\n",
    "#     model = KNeighborsRegressor(n_neighbors=n,n_jobs=n_jobs,leaf_size=10)\n",
    "#     model.fit(x_train, y_train)\n",
    "#     score_train = model.score(x_train, y_train)\n",
    "#     scores_train[n-1] = score_train\n",
    "\n",
    "#     score_test = model.score(x_test, y_test)\n",
    "#     scores_test[n-1] = score_test\n",
    "\n",
    "#     variance[n-1] = score_train - score_test\n",
    "#     #     print(\"Score bij diepte {}: {:.2f}%.\".format(depth, score))\n",
    "\n",
    "# fig, ax = plt.subplots(1, dpi=100)\n",
    "\n",
    "# line1, = ax.plot(neighbours, scores_train, label='Train')\n",
    "# line2, = ax.plot(neighbours, scores_test, label='Test')\n",
    "# line3, = ax.plot(neighbours, variance, label='Variance')\n",
    "\n",
    "# ax.legend()\n",
    "# ax.set_xlabel(\"diepte (aantal lagen)\")\n",
    "# ax.set_ylabel(\"Bias-Variance\")\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Decision Tree regressie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bij decision tree regressie kun je zelf de parameter voor max_depth aanpassen. Hieronder tonen we twee voorbeelden waarbij bij het eerste geval de max_depth op 2 staat en bij het tweede geval op 37. Hierna vergelijken we de scores van de twee decision trees. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree1 = DecisionTreeRegressor(max_depth=2)\n",
    "dtree2 = DecisionTreeRegressor(max_depth=37)\n",
    "dtree1.fit(x_train, y_train)\n",
    "dtree2.fit(x_train, y_train)\n",
    "\n",
    "# Code Lines 5 to 6: Predict on training data\n",
    "tr1 = dtree1.predict(x_train)\n",
    "tr2 = dtree2.predict(x_train) \n",
    "\n",
    "#Code Lines 7 to 8: Predict on testing data\n",
    "y1 = dtree1.predict(x_test)\n",
    "y2 = dtree2.predict(x_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score en RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Score decision tree 1, max_depth 2\")\n",
    "print(np.sqrt(mean_squared_error(y_test,y1))) \n",
    "print(r2_score(y_test, y1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Score decision tree 2, max_depth 37\")\n",
    "print(np.sqrt(mean_squared_error(y_test,y2))) \n",
    "print(r2_score(y_test, y2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Om overfitten te voorkomen bij een te hoge max_depth en wel de beste score te behouden, kiezen we voor deze hyperparamter het getal 8. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dtree_final = DecisionTreeRegressor(max_depth=8)\n",
    "dtree_final.fit(x_train, y_train)\n",
    "\n",
    "y_final = dtree_final.predict(x_test)\n",
    "\n",
    "print(r2_score(y_test, y_final))\n",
    "print(np.sqrt(mean_squared_error(y_test,y_final))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias/Variance trade-off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_depth = 20\n",
    "# scores_train = np.zeros(max_depth)\n",
    "# scores_test = np.zeros(max_depth)\n",
    "# variance = np.zeros(max_depth)\n",
    "\n",
    "# depths = range(1, max_depth + 1)\n",
    "# for depth in depths:\n",
    "#     model = DecisionTreeRegressor(max_depth=depth, min_samples_split=20)\n",
    "#     model.fit(x_train, y_train)\n",
    "    \n",
    "#     score_train = model.score(x_train, y_train)\n",
    "#     scores_train[depth-1] = score_train\n",
    "\n",
    "#     score_test = model.score(x_test, y_test)\n",
    "#     scores_test[depth-1] = score_test\n",
    "\n",
    "#     variance[depth-1] = score_train - score_test\n",
    "#     #     print(\"Score bij diepte {}: {:.2f}%.\".format(depth, score))\n",
    "\n",
    "# fig, ax = plt.subplots(1, dpi=100)\n",
    "\n",
    "# line1, = ax.plot(depths, scores_train, label='Train')\n",
    "# line2, = ax.plot(depths, scores_test, label='Test')\n",
    "# line3, = ax.plot(depths, variance, label='Variance')\n",
    "\n",
    "# ax.legend()\n",
    "# ax.set_xlabel(\"diepte (aantal lagen)\")\n",
    "# ax.set_ylabel(\"Bias-Variance\")\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Random Forest regressie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf = RandomForestRegressor(max_features=None, n_estimators=50, max_leaf_nodes=48, oob_score=True, random_state=100,n_jobs=n_jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score en RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf.fit(x_train, y_train) \n",
    "pred_train_rf= model_rf.predict(x_train)\n",
    "print('Train RMSE:',np.sqrt(mean_squared_error(y_train,pred_train_rf)))\n",
    "print('Train R^2 score:',r2_score(y_train, pred_train_rf))\n",
    "pred_test_rf= model_rf.predict(x_test)\n",
    "print('Test RMSE:',np.sqrt(mean_squared_error(y_test,pred_test_rf)))\n",
    "print('Test R^2 score:',r2_score(y_test, pred_test_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aangezien dit model het best scoort wat betreft de r2 score en de RMSE, kiezen we dit model om de voorspellingen mee te gaan doen. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Probability functie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We willen graag weten hoe zeker het model is van een voorspelling: hiervoor gebruiken we de probability functie. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(\n",
    "    max_features=None, n_estimators=50, max_leaf_nodes=48, oob_score=True, random_state=100,n_jobs=n_jobs\n",
    "                             ).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nodeScaler(x,depth):\n",
    "    x_ar = x.to_numpy().nonzero()[0]\n",
    "    flr = np.floor(x_ar / depth)\n",
    "    x = (x_ar - (flr * depth)).astype(int).max()\n",
    "    return x\n",
    "\n",
    "def random_forest_regressor_predict_proba(X_train, y_train, X_test, m):\n",
    "    \"\"\"Trains DecisionTreeRegressor model and predicts probabilities of each y.\n",
    "\n",
    "    Args:\n",
    "        X_train: Training features.\n",
    "        y_train: Training labels.\n",
    "        X_test: New data to predict on.\n",
    "        **kwargs: Other arguments passed to DecisionTreeRegressor.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with columns for record_id (row of X_test), y \n",
    "        (predicted value), and prob (of that y value).\n",
    "        The sum of prob equals 1 for each record_id.\n",
    "    \"\"\"\n",
    "    n_trees = m.get_params()['n_estimators']\n",
    "    # Get y values corresponding to each node.\n",
    "    node_ys = pd.DataFrame({'node_id':m.apply(X_train).flatten(), 'duur': np.repeat(y_train,n_trees)})\n",
    "    # Calculate probability as 1 / number of y values per node.\n",
    "    node_ys['prob'] = 1 / node_ys.groupby(node_ys.node_id).transform('count')\n",
    "    \n",
    "    # Aggregate per node-y, in case of multiple training records with the same y.\n",
    "    node_ys_dedup = node_ys.groupby(['node_id', 'duur']).prob.sum().to_frame()\\\n",
    "        .reset_index()\n",
    "    node_ys_dedup['node_id'].astype(int)\n",
    "#     node_ys_dedup.to_csv('nodes_prob.csv')\n",
    "\n",
    "    depth = m.decision_path(X_test)[1][1]\n",
    "    leaf = pd.DataFrame(columns=['node_id'])\n",
    "    path = m.decision_path(X_test)[0].toarray()\n",
    "    for i in range(1,len(m.decision_path(X_test)[1][1:])):\n",
    "        start = m.decision_path(X_test)[1][i-1]\n",
    "        end = m.decision_path(X_test)[1][i]\n",
    "        leaf = leaf.append(pd.DataFrame(path[:,start:end]).apply(\n",
    "            lambda x: nodeScaler(x,depth), axis=1).to_frame(\n",
    "        name='node_id'))\n",
    "     \n",
    "    leaf['record_id'] = leaf.index\n",
    "    # Merge with y values and drop node_id.\n",
    "    leaf = leaf.merge(node_ys_dedup, on='node_id').drop(\n",
    "        'node_id', axis=1)\n",
    "    duur = leaf.groupby(['record_id','duur'])\n",
    "    return (duur.sum() / duur.count()).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = random_forest_regressor_predict_proba(x_train, y_train, x_test ,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = random_forest_regressor_predict_proba(x_train, y_train, x_test[:1],model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 3\n",
    "res = random_forest_regressor_predict_proba(x_train, y_train, x_test.iloc[[i]] ,model)\n",
    "display(res[res['record_id'] == 0].sort_values('prob',ascending=False)[['duur','prob']][:10])\n",
    "# display(x_train.iloc[[i]])\n",
    "print(model.predict(x_test.iloc[[i]]))\n",
    "print(y_test.iloc[[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = 'finalized_model_lin.sav'\n",
    "# pickle.dump(dtree_final, open(filename, 'wb'))\n",
    "# filename = 'finalized_model_dectreereg.sav'\n",
    "# pickle.dump(dtree_final, open(filename, 'wb'))\n",
    "# filename = 'finalized_model_knearest.sav'\n",
    "# pickle.dump(knearestModel, open(filename, 'wb'))\n",
    "# df.to_csv('sap_storing_data_hu_project_norm.csv', columns=features)\n",
    "\n",
    "filename = 'rand_for.sav'\n",
    "pickle.dump(model_rf, open(filename, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "language": "python",
   "name": "python38364bit5cdb2531dd3545ea9b3fd1a8a995abfc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
