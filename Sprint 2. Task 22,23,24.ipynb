{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User story 4.<br><br>\n",
    "Om te bepalen welk model we gaan gebruiken moeten we weten wat het verschil is in die modellen en wat het beste past bij het probleem en wat in de beste score resulteerd. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "import datetime as date\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "n_jobs = 16 #set number of jobs equal or -1 the amount of cpu cores you have to speed up this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usefullcols = ['stm_mon_nr','stm_sap_meld_ddt','stm_status_melding_sap','stm_km_van_mld','stm_km_tot_mld','stm_km_van_gst',\n",
    "'stm_km_tot_gst','stm_fh_tijd','stm_sap_melddatum','stm_aanngeb_tijd','stm_aanntpl_tijd','stm_arbeid',\n",
    "'stm_progfh_in_tijd','stm_progfh_in_invoer_tijd','stm_progfh_in_duur','stm_sap_storeindtijd','stm_progfh_gw_tijd',\n",
    "'stm_reactie_duur','stm_progfh_gw_duur','stm_progfh_gw_teller','stm_afspr_aanvangdd','stm_afspr_aanvangtijd',\n",
    "'stm_fh_duur','stm_evb','stm_sap_meldtijd','stm_sap_meldtekst_lang','stm_prioriteit','stm_oh_pg_gst',\n",
    "'stm_sap_meldtekst','stm_techn_gst','stm_contractgeb_gst','stm_tao_indicator','stm_geo_mld','stm_functiepl_mld',\n",
    "'stm_geo_mld_uit_functiepl','stm_aanngeb_ddt','stm_aanngeb_dd','stm_oorz_code','stm_oorz_groep','stm_oorz_tkst',\n",
    "'stm_fh_dd','stm_fh_status','stm_geo_gst','stm_functiepl_gst','stm_geo_gst_uit_functiepl','stm_fh_ddt',\n",
    "'stm_aanntpl_dd','stm_techn_mld','stm_sap_storeinddatum','stm_equipm_nr_mld','stm_equipm_soort_mld',\n",
    "'stm_equipm_omschr_mld','stm_sap_storeind_ddt','stm_contractgeb_mld','stm_equipm_nr_gst','stm_equipm_soort_gst',\n",
    "'stm_equipm_omschr_gst','stm_progfh_in_invoer_dat','stm_progfh_in_datum','stm_oorz_tekst_kort','stm_dstrglp_naar',\n",
    "'stm_tao_indicator_vorige','stm_vl_post','stm_dstrglp_van','stm_pplg_van','stm_tao_soort_mutatie',\n",
    "'stm_progfh_gw_lwd_tijd','stm_pplg_naar','stm_progfh_gw_lwd_datum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('sap_storing_data_hu_project.csv',usecols=usefullcols, low_memory=True)\n",
    "# df = pd.read_csv('sap_storing.csv',usecols=usefullcols, low_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['stm_prioriteit','stm_oorz_code','stm_oorz_groep','stm_equipm_nr_*','stm_equipm_soort_*','stm_geo_*']\n",
    "target = 'duur'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = date.datetime.today()\n",
    "zeroTimeDiff = now - now\n",
    "\n",
    "df.drop_duplicates(subset=['stm_mon_nr'], keep='last',inplace = True)\n",
    "\n",
    "df['stm_aanntpl_ddt'] = pd.to_datetime(df['stm_aanntpl_dd']+' '+df['stm_aanntpl_tijd'], format='%d/%m/%Y %H:%M:%S')\n",
    "df['stm_fh_ddt'] = pd.to_datetime(df['stm_fh_ddt'], format='%d/%m/%Y %H:%M:%S')\n",
    "\n",
    "df.dropna(subset=['stm_aanntpl_dd','stm_aanntpl_tijd','stm_fh_ddt'],inplace=True)\n",
    "\n",
    "df['duur'] = df['stm_fh_ddt'] - df['stm_aanntpl_ddt']\n",
    "df.dropna(subset=['duur'],inplace=True)\n",
    "\n",
    "# Meldingen waar de oplossing in de toekomst is zijn onzin.\n",
    "# df[df['stm_sap_storeind_ddt'] >= now][['stm_sap_storeind_ddt','stm_sap_meld_ddt']]\n",
    "# df.drop(df[df['stm_sap_storeind_ddt'] >= now][['stm_sap_storeind_ddt','stm_sap_meld_ddt']].index,inplace=True)\n",
    "\n",
    "# Rijen waar het probleem sneller is opgelost dan 5 minuten (en ook de meldingen tijd) zijn onbetrouwbaar.\n",
    "df.drop(df[df['duur'] <= date.timedelta(minutes=5)].index, inplace = True)\n",
    "\n",
    "# # Alles wat langer dan een dag duurt is niet urgent genoeg en dus niet nuttig.\n",
    "df.drop(df[df['duur'] > date.timedelta(hours=6)].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df[['duur']])\n",
    "print(df['duur'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge similar columns together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dubbleCol = ['stm_equipm_omschr_*', 'stm_equipm_soort_*', 'stm_equipm_nr_*', \n",
    "             'stm_geo_*_uit_functiepl', 'stm_functiepl_*', 'stm_geo_*',\n",
    "            'stm_km_van_*','stm_km_tot_*',\n",
    "            'stm_contractgeb_*','stm_techn_*']\n",
    "original = 'mld'\n",
    "optional = ['gst'] # Order of least to most important\n",
    "for colPH in dubbleCol:\n",
    "    colOg = colPH.replace('*',original)\n",
    "    \n",
    "    for option in optional:\n",
    "        colOp = colPH.replace('*',option)\n",
    "        df[colPH] = np.where(df[colOp].isna(), df[colOg], df[colOp])\n",
    "        df.drop(columns=[colOp],inplace=True)\n",
    "    df.drop(columns=[colOg],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Het vullen van interresante colommen.\n",
    "Correcte type waardes geven aan de colommen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['stm_prioriteit'] = df['stm_prioriteit'].fillna(1) # Laagste prio\n",
    "df['stm_oorz_code'] = df['stm_oorz_code'].fillna(299) # 'Niet gemeld' code\n",
    "df['stm_oorz_groep'] = df['stm_oorz_groep'].fillna('x')\n",
    "df['stm_fh_status'] = df['stm_fh_status'].fillna(1) # Median of values\n",
    "df['stm_aanngeb_tijd'] = df['stm_aanngeb_tijd'].fillna(df['stm_sap_meldtijd']) # Aannemer beltijd gelijk met melding zetten.\n",
    "df['stm_progfh_in_invoer_tijd'] = df['stm_progfh_in_invoer_tijd'].fillna(df['stm_aanngeb_tijd']) # Tijd van prognose op beltijd zetten.\n",
    "df['stm_equipm_nr_*'] = df['stm_equipm_nr_*'].fillna(0)\n",
    "df['stm_equipm_soort_*'] = df['stm_equipm_soort_*'].fillna('x')\n",
    "df['stm_contractgeb_*'] = df['stm_contractgeb_*'].fillna(0)\n",
    "df['stm_progfh_gw_teller'] = df['stm_progfh_gw_teller'].fillna(0)\n",
    "\n",
    "df['stm_prioriteit'] = df['stm_prioriteit'].astype(int)\n",
    "df['stm_oorz_code'] = df['stm_oorz_code'].astype(int)\n",
    "df['stm_fh_status'] = df['stm_fh_status'].astype(int)\n",
    "df['stm_fh_duur'] = df['stm_fh_duur'].astype(int)\n",
    "df['stm_progfh_gw_teller'] = df['stm_progfh_gw_teller'].astype(int)\n",
    "df['stm_equipm_nr_*'] = df['stm_equipm_nr_*'].astype(int)\n",
    "df['stm_contractgeb_*'] = df['stm_contractgeb_*'].astype(int)\n",
    "\n",
    "df['duur'] = df['duur'].apply(lambda x: x.seconds / 60)\n",
    "df['duur'] = df['duur'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amntInTime = df[df['duur'] < date.timedelta(hours=2,minutes=17).seconds / 60].count()[0]\n",
    "total = df.shape[0]\n",
    "baseline = date.timedelta(hours=2,minutes=17).seconds / 60\n",
    "pred = [int(baseline)]*df[['duur']].shape[0]\n",
    "\n",
    "print(f'{amntInTime / total * 100}% van de tijd heeft het baseline model het goed.')\n",
    "print('Root mean squared error:',np.sqrt(mean_squared_error(df['duur'],pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_ozgr = LabelEncoder()\n",
    "le_ozgr.fit(df['stm_oorz_groep'].unique())\n",
    "df['stm_oorz_groep'] = le_ozgr.transform(df['stm_oorz_groep'])\n",
    "# df['stm_oorz_groep'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_equipsrt = LabelEncoder()\n",
    "le_equipsrt.fit(df['stm_equipm_soort_*'].unique())\n",
    "df['stm_equipm_soort_*'] = le_equipsrt.transform(df['stm_equipm_soort_*'])\n",
    "# df['stm_equipm_soort_*'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dOC = pd.get_dummies(df['stm_oorz_code'],prefix='oorz_code')\n",
    "dOG = pd.get_dummies(df['stm_oorz_groep'],prefix='oorz_groep')\n",
    "eqs = pd.get_dummies(df['stm_equipm_soort_*'])\n",
    "geo = pd.get_dummies(df['stm_geo_*'],prefix='geo')\n",
    "\n",
    "dummies = pd.concat([df['stm_prioriteit'],geo,dOC, dOG, eqs],axis=1)\n",
    "\n",
    "display(dummies)\n",
    "dummies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(df[[target]])\n",
    "# display(df[[target]].describe())\n",
    "# print(df[[target]].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dummies\n",
    "# X = df[features]\n",
    "Y = df[target]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train,y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linearModel = linear_model.LinearRegression().fit(x_train,y_train)\n",
    "linYPrediction = linearModel.predict(x_test)\n",
    "print(f'Score: {linearModel.score(x_test,y_test)}')\n",
    "print(f'Mean squared error: {np.sqrt(mean_squared_error(y_test,linYPrediction))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(x_test[:5])\n",
    "display(y_test[:5])\n",
    "linYPrediction[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ridgeModel = linear_model.Ridge(alpha=1).fit(x_train,y_train)\n",
    "ridgeYPrediction = ridgeModel.predict(x_test)\n",
    "print(f'Score: {ridgeModel.score(x_test,y_test)}')\n",
    "print(f'Mean squared error: {np.sqrt(mean_squared_error(y_test,ridgeYPrediction))}')\n",
    "print(ridgeModel.get_params())\n",
    "print(ridgeModel.get_params(deep=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knearestModel = KNeighborsRegressor(n_neighbors=2,n_jobs=n_jobs).fit(x_train,y_train)\n",
    "# knearestYPrediction = knearestModel.predict(x_test)\n",
    "# print(f'Score: {knearestModel.score(x_test,y_test)}')\n",
    "# print(f'Mean squared error: {np.sqrt(mean_squared_error(y_test,knearestYPrediction))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_neighbours = 10\n",
    "# scores_train = np.zeros(max_neighbours)\n",
    "# scores_test = np.zeros(max_neighbours)\n",
    "# variance = np.zeros(max_neighbours)\n",
    "\n",
    "# neighbours = range(1, max_neighbours + 1)\n",
    "# for n in neighbours:\n",
    "#     print(f\"Starting with run:{n}\")\n",
    "#     model = KNeighborsRegressor(n_neighbors=n,n_jobs=n_jobs,leaf_size=10)\n",
    "#     model.fit(x_train, y_train)\n",
    "#     score_train = model.score(x_train, y_train)\n",
    "#     scores_train[n-1] = score_train\n",
    "\n",
    "#     score_test = model.score(x_test, y_test)\n",
    "#     scores_test[n-1] = score_test\n",
    "\n",
    "#     variance[n-1] = score_train - score_test\n",
    "#     #     print(\"Score bij diepte {}: {:.2f}%.\".format(depth, score))\n",
    "\n",
    "# fig, ax = plt.subplots(1, dpi=100)\n",
    "\n",
    "# line1, = ax.plot(neighbours, scores_train, label='Train')\n",
    "# line2, = ax.plot(neighbours, scores_test, label='Test')\n",
    "# line3, = ax.plot(neighbours, variance, label='Variance')\n",
    "\n",
    "# ax.legend()\n",
    "# ax.set_xlabel(\"diepte (aantal lagen)\")\n",
    "# ax.set_ylabel(\"Bias-Variance\")\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-linear regression trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree1 = DecisionTreeRegressor(max_depth=2)\n",
    "dtree2 = DecisionTreeRegressor(max_depth=37)\n",
    "dtree1.fit(x_train, y_train)\n",
    "dtree2.fit(x_train, y_train)\n",
    "\n",
    "# Code Lines 5 to 6: Predict on training data\n",
    "tr1 = dtree1.predict(x_train)\n",
    "tr2 = dtree2.predict(x_train) \n",
    "\n",
    "#Code Lines 7 to 8: Predict on testing data\n",
    "y1 = dtree1.predict(x_test)\n",
    "y2 = dtree2.predict(x_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sqrt(mean_squared_error(y_train,tr1))) \n",
    "print(r2_score(y_train, tr1))\n",
    "\n",
    "print(np.sqrt(mean_squared_error(y_test,y1))) \n",
    "print(r2_score(y_test, y1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sqrt(mean_squared_error(y_train,tr2))) \n",
    "print(r2_score(y_train, tr2))\n",
    "\n",
    "print(np.sqrt(mean_squared_error(y_test,y2))) \n",
    "print(r2_score(y_test, y2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_depth = 20\n",
    "# scores_train = np.zeros(max_depth)\n",
    "# scores_test = np.zeros(max_depth)\n",
    "# variance = np.zeros(max_depth)\n",
    "\n",
    "# depths = range(1, max_depth + 1)\n",
    "# for depth in depths:\n",
    "#     model = DecisionTreeRegressor(max_depth=depth, min_samples_split=20)\n",
    "#     model.fit(x_train, y_train)\n",
    "    \n",
    "#     score_train = model.score(x_train, y_train)\n",
    "#     scores_train[depth-1] = score_train\n",
    "\n",
    "#     score_test = model.score(x_test, y_test)\n",
    "#     scores_test[depth-1] = score_test\n",
    "\n",
    "#     variance[depth-1] = score_train - score_test\n",
    "#     #     print(\"Score bij diepte {}: {:.2f}%.\".format(depth, score))\n",
    "\n",
    "# fig, ax = plt.subplots(1, dpi=100)\n",
    "\n",
    "# line1, = ax.plot(depths, scores_train, label='Train')\n",
    "# line2, = ax.plot(depths, scores_test, label='Test')\n",
    "# line3, = ax.plot(depths, variance, label='Variance')\n",
    "\n",
    "# ax.legend()\n",
    "# ax.set_xlabel(\"diepte (aantal lagen)\")\n",
    "# ax.set_ylabel(\"Bias-Variance\")\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dtree_final = DecisionTreeRegressor(max_depth=8)\n",
    "dtree_final.fit(x_train, y_train)\n",
    "\n",
    "y_final = dtree_final.predict(x_test)\n",
    "\n",
    "print(r2_score(y_test, y_final))\n",
    "print(np.sqrt(mean_squared_error(y_test,y_final))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf = RandomForestRegressor(max_features=None, n_estimators=50, max_leaf_nodes=48, oob_score=True, random_state=100,n_jobs=n_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf.fit(x_train, y_train) \n",
    "pred_train_rf= model_rf.predict(x_train)\n",
    "print('Train RMSE:',np.sqrt(mean_squared_error(y_train,pred_train_rf)))\n",
    "print('Train R^2 score:',r2_score(y_train, pred_train_rf))\n",
    "pred_test_rf= model_rf.predict(x_test)\n",
    "print('Test RMSE:',np.sqrt(mean_squared_error(y_test,pred_test_rf)))\n",
    "print('Test R^2 score:',r2_score(y_test, pred_test_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(\n",
    "    max_features=None, n_estimators=50, max_leaf_nodes=48, oob_score=True, random_state=100,n_jobs=n_jobs\n",
    "                             ).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_regressor_predict_proba(X_train, y_train, X_test, m):\n",
    "    \"\"\"Trains DecisionTreeRegressor model and predicts probabilities of each y.\n",
    "\n",
    "    Args:\n",
    "        X_train: Training features.\n",
    "        y_train: Training labels.\n",
    "        X_test: New data to predict on.\n",
    "        **kwargs: Other arguments passed to DecisionTreeRegressor.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with columns for record_id (row of X_test), y \n",
    "        (predicted value), and prob (of that y value).\n",
    "        The sum of prob equals 1 for each record_id.\n",
    "    \"\"\"\n",
    "    # Get y values corresponding to each node.\n",
    "    node_ys = pd.DataFrame({'node_id':m.apply(X_train)[:,0], 'duur': y_train})\n",
    "    # Calculate probability as 1 / number of y values per node.\n",
    "    node_ys['prob'] = 1 / node_ys.groupby(node_ys.node_id).transform('count')\n",
    "    # Aggregate per node-y, in case of multiple training records with the same y.\n",
    "    node_ys_dedup = node_ys.groupby(['node_id', 'duur']).prob.sum().to_frame()\\\n",
    "        .reset_index()\n",
    "    \n",
    "    dept = m.decision_path(X_test)[1][1]\n",
    "    leaf = pd.DataFrame(m.decision_path(X_test)[0].toarray()[:,:dept]).apply(\n",
    "        lambda x:x.to_numpy().nonzero()[0].max(), axis=1).to_frame(\n",
    "            name='node_id')\n",
    "    leaf['record_id'] = leaf.index\n",
    "    # Merge with y values and drop node_id.\n",
    "    return leaf.merge(node_ys_dedup, on='node_id').drop(\n",
    "        'node_id', axis=1).sort_values(['record_id', 'duur'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = random_forest_regressor_predict_proba(x_train, y_train, x_test[:1],model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[res['record_id'] == 0].sort_values('prob',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = 'finalized_model_lin.sav'\n",
    "# pickle.dump(dtree_final, open(filename, 'wb'))\n",
    "# filename = 'finalized_model_dectreereg.sav'\n",
    "# pickle.dump(dtree_final, open(filename, 'wb'))\n",
    "# filename = 'finalized_model_knearest.sav'\n",
    "# pickle.dump(knearestModel, open(filename, 'wb'))\n",
    "# df.to_csv('sap_storing_data_hu_project_norm.csv', columns=features)\n",
    "\n",
    "filename = 'rand_for.sav'\n",
    "pickle.dump(model_rf, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = date.timedelta(hours=2,minutes=17)\n",
    "baseline = baseline.seconds / 60\n",
    "pred = [int(baseline)]*df[[target]].shape[0]\n",
    "r2_score(df[[target]],pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "language": "python",
   "name": "python38364bit5cdb2531dd3545ea9b3fd1a8a995abfc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
